{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169ea208",
   "metadata": {},
   "source": [
    "# 06 LightGBM: Optunaあり vs なし\n",
    "\n",
    "`00_prepare_data.ipynb` で作成した Titanic の Train/Test を使い、\n",
    "- PatternA: 固定ハイパーパラメータ（Optunaなし）\n",
    "- PatternB: Optunaでハイパーパラメータ探索\n",
    "を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61c1fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, roc_auc_score\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except ImportError as exc:\n",
    "    raise ImportError('optuna が未インストールです。`uv pip install optuna` を実行してください。') from exc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_SPLITS = 5\n",
    "N_TRIALS = 30\n",
    "TIMEOUT_SEC = 300\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0360fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (19536, 14)\n",
      "Test shape : (29306, 14)\n",
      "Classes    : [0, 1]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/processed/classification_train.csv')\n",
    "test_df = pd.read_csv('data/processed/classification_test.csv')\n",
    "\n",
    "X_train_full = train_df.drop(columns=['target'])\n",
    "y_train_full = train_df['target'].astype(int)\n",
    "X_test = test_df.drop(columns=['target'])\n",
    "y_test = test_df['target'].astype(int)\n",
    "\n",
    "class_labels = np.sort(y_train_full.unique())\n",
    "num_class = len(class_labels)\n",
    "is_binary = num_class == 2\n",
    "\n",
    "print(f'Train shape: {X_train_full.shape}')\n",
    "print(f'Test shape : {X_test.shape}')\n",
    "print(f'Classes    : {class_labels.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9c603fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lgbm_params(seed, custom_params=None):\n",
    "    base_params = {\n",
    "        'n_estimators': 300,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': seed,\n",
    "        'bagging_seed': seed,\n",
    "        'feature_fraction_seed': seed,\n",
    "        'data_random_seed': seed,\n",
    "        'deterministic': True,\n",
    "        'force_col_wise': True\n",
    "    }\n",
    "\n",
    "    if is_binary:\n",
    "        base_params.update({\n",
    "            'objective': 'binary'\n",
    "        })\n",
    "    else:\n",
    "        base_params.update({\n",
    "            'objective': 'multiclass',\n",
    "            'num_class': num_class\n",
    "        })\n",
    "\n",
    "    if custom_params is not None:\n",
    "        base_params.update(custom_params)\n",
    "\n",
    "    return base_params\n",
    "\n",
    "def calc_auc(y_true, proba):\n",
    "    if is_binary:\n",
    "        return roc_auc_score(y_true, proba[:, 1])\n",
    "    return roc_auc_score(y_true, proba, multi_class='ovr', average='macro')\n",
    "\n",
    "def evaluate_pattern(method_name, custom_params=None):\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    fold_rows = []\n",
    "    test_proba_folds = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_train_full, y_train_full), start=1):\n",
    "        X_tr = X_train_full.iloc[tr_idx]\n",
    "        y_tr = y_train_full.iloc[tr_idx]\n",
    "        X_va = X_train_full.iloc[va_idx]\n",
    "        y_va = y_train_full.iloc[va_idx]\n",
    "\n",
    "        params = make_lgbm_params(SEED + fold, custom_params=custom_params)\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric='binary_logloss' if is_binary else 'multi_logloss',\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        )\n",
    "\n",
    "        tr_proba = model.predict_proba(X_tr)\n",
    "        tr_pred = model.predict(X_tr)\n",
    "        va_proba = model.predict_proba(X_va)\n",
    "        va_pred = model.predict(X_va)\n",
    "        te_proba = model.predict_proba(X_test)\n",
    "        te_pred = np.argmax(te_proba, axis=1)\n",
    "\n",
    "        test_proba_folds.append(te_proba)\n",
    "\n",
    "        for metrics in [\n",
    "            {\n",
    "                'Split': 'Train',\n",
    "                'Accuracy': accuracy_score(y_tr, tr_pred),\n",
    "                'F1_macro': f1_score(y_tr, tr_pred, average='macro'),\n",
    "                'LogLoss': log_loss(y_tr, tr_proba, labels=class_labels),\n",
    "                'AUC': calc_auc(y_tr, tr_proba)\n",
    "            },\n",
    "            {\n",
    "                'Split': 'Valid',\n",
    "                'Accuracy': accuracy_score(y_va, va_pred),\n",
    "                'F1_macro': f1_score(y_va, va_pred, average='macro'),\n",
    "                'LogLoss': log_loss(y_va, va_proba, labels=class_labels),\n",
    "                'AUC': calc_auc(y_va, va_proba)\n",
    "            },\n",
    "            {\n",
    "                'Split': 'Test',\n",
    "                'Accuracy': accuracy_score(y_test, te_pred),\n",
    "                'F1_macro': f1_score(y_test, te_pred, average='macro'),\n",
    "                'LogLoss': log_loss(y_test, te_proba, labels=class_labels),\n",
    "                'AUC': calc_auc(y_test, te_proba)\n",
    "            }\n",
    "        ]:\n",
    "            fold_rows.append({\n",
    "                'Method': method_name,\n",
    "                'Fold': fold,\n",
    "                'Split': metrics['Split'],\n",
    "                'Accuracy': metrics['Accuracy'],\n",
    "                'F1_macro': metrics['F1_macro'],\n",
    "                'LogLoss': metrics['LogLoss'],\n",
    "                'AUC': metrics['AUC']\n",
    "            })\n",
    "\n",
    "    fold_df = pd.DataFrame(fold_rows)\n",
    "    mean_df = fold_df.groupby(['Method', 'Split'], as_index=False)[['Accuracy', 'F1_macro', 'LogLoss', 'AUC']].mean()\n",
    "\n",
    "    test_proba_mean = np.mean(np.stack(test_proba_folds, axis=0), axis=0)\n",
    "    test_pred_mean = np.argmax(test_proba_mean, axis=1)\n",
    "\n",
    "    return fold_df, mean_df, test_pred_mean, test_proba_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c6c16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial):\n",
    "    trial_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 8, 128),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 80),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True)\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    fold_losses = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_train_full, y_train_full), start=1):\n",
    "        X_tr = X_train_full.iloc[tr_idx]\n",
    "        y_tr = y_train_full.iloc[tr_idx]\n",
    "        X_va = X_train_full.iloc[va_idx]\n",
    "        y_va = y_train_full.iloc[va_idx]\n",
    "\n",
    "        params = make_lgbm_params(SEED + fold, custom_params=trial_params)\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric='binary_logloss' if is_binary else 'multi_logloss',\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
    "        )\n",
    "\n",
    "        va_proba = model.predict_proba(X_va)\n",
    "        fold_loss = log_loss(y_va, va_proba, labels=class_labels)\n",
    "        fold_losses.append(fold_loss)\n",
    "\n",
    "    return float(np.mean(fold_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b92015db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:48:34,766]\u001b[0m A new study created in memory with name: lgbm_optuna_vs_no_optuna\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:48:40,318]\u001b[0m Trial 0 finished with value: 0.2906252862761691 and parameters: {'n_estimators': 465, 'learning_rate': 0.040593731829724554, 'num_leaves': 117, 'min_child_samples': 70, 'subsample': 0.8834787702202254, 'colsample_bytree': 0.7451312322613973, 'reg_alpha': 4.521620606250671e-06, 'reg_lambda': 4.549274853361652}. Best is trial 0 with value: 0.2906252862761691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:48:46,620]\u001b[0m Trial 1 finished with value: 0.28689464678030036 and parameters: {'n_estimators': 223, 'learning_rate': 0.022331611793196066, 'num_leaves': 91, 'min_child_samples': 8, 'subsample': 0.7511154629960948, 'colsample_bytree': 0.7576752964847797, 'reg_alpha': 0.44034958149128756, 'reg_lambda': 0.018448777700593222}. Best is trial 1 with value: 0.28689464678030036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:48:49,165]\u001b[0m Trial 2 finished with value: 0.2891999092630334 and parameters: {'n_estimators': 535, 'learning_rate': 0.11203339059517219, 'num_leaves': 93, 'min_child_samples': 42, 'subsample': 0.9160385530571394, 'colsample_bytree': 0.6560475208497415, 'reg_alpha': 9.510682412487011e-07, 'reg_lambda': 3.6148972734073364e-05}. Best is trial 1 with value: 0.28689464678030036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:48:51,814]\u001b[0m Trial 3 finished with value: 0.28375550652207127 and parameters: {'n_estimators': 298, 'learning_rate': 0.057667786950729445, 'num_leaves': 43, 'min_child_samples': 20, 'subsample': 0.6486954697961916, 'colsample_bytree': 0.8024560769313318, 'reg_alpha': 9.309909645200098e-05, 'reg_lambda': 7.131050644334982e-06}. Best is trial 3 with value: 0.28375550652207127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:48:53,480]\u001b[0m Trial 4 finished with value: 0.2853672146494864 and parameters: {'n_estimators': 244, 'learning_rate': 0.13435433645841616, 'num_leaves': 30, 'min_child_samples': 25, 'subsample': 0.881046576838422, 'colsample_bytree': 0.9395131339494183, 'reg_alpha': 0.00017750719056099115, 'reg_lambda': 4.611258149869271e-05}. Best is trial 3 with value: 0.28375550652207127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:48:59,312]\u001b[0m Trial 5 finished with value: 0.2967258879807258 and parameters: {'n_estimators': 222, 'learning_rate': 0.01591566658603101, 'num_leaves': 82, 'min_child_samples': 66, 'subsample': 0.7657220632119471, 'colsample_bytree': 0.8371806859817134, 'reg_alpha': 8.450140904873919e-06, 'reg_lambda': 0.04732185359143848}. Best is trial 3 with value: 0.28375550652207127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:02,057]\u001b[0m Trial 6 finished with value: 0.2875047945835171 and parameters: {'n_estimators': 412, 'learning_rate': 0.08286802213359534, 'num_leaves': 73, 'min_child_samples': 27, 'subsample': 0.8668483039913969, 'colsample_bytree': 0.8535608369327081, 'reg_alpha': 0.9455159643057233, 'reg_lambda': 0.0002774632266516944}. Best is trial 3 with value: 0.28375550652207127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:04,687]\u001b[0m Trial 7 finished with value: 0.2925544249109241 and parameters: {'n_estimators': 345, 'learning_rate': 0.10018211892352298, 'num_leaves': 113, 'min_child_samples': 46, 'subsample': 0.7571561945301667, 'colsample_bytree': 0.9982542855137423, 'reg_alpha': 5.056665661492334e-07, 'reg_lambda': 0.0011425706350837253}. Best is trial 3 with value: 0.28375550652207127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:07,622]\u001b[0m Trial 8 finished with value: 0.3053814811556008 and parameters: {'n_estimators': 179, 'learning_rate': 0.01510313175984086, 'num_leaves': 39, 'min_child_samples': 38, 'subsample': 0.6967571422007394, 'colsample_bytree': 0.6988497360991459, 'reg_alpha': 0.619680103333132, 'reg_lambda': 0.02772478567694382}. Best is trial 3 with value: 0.28375550652207127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:09,239]\u001b[0m Trial 9 finished with value: 0.29999813375201645 and parameters: {'n_estimators': 133, 'learning_rate': 0.027236162823289518, 'num_leaves': 19, 'min_child_samples': 49, 'subsample': 0.6475692778273117, 'colsample_bytree': 0.7378258017541025, 'reg_alpha': 0.010640440799733976, 'reg_lambda': 1.584683131825935e-05}. Best is trial 3 with value: 0.28375550652207127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:12,664]\u001b[0m Trial 10 finished with value: 0.2828402145348072 and parameters: {'n_estimators': 333, 'learning_rate': 0.05418702247439193, 'num_leaves': 52, 'min_child_samples': 8, 'subsample': 0.6148151971385892, 'colsample_bytree': 0.6183624108053116, 'reg_alpha': 2.0732591179532584e-08, 'reg_lambda': 3.131493969602774e-07}. Best is trial 10 with value: 0.2828402145348072.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:17,083]\u001b[0m Trial 11 finished with value: 0.28285686221771805 and parameters: {'n_estimators': 335, 'learning_rate': 0.05452816710022316, 'num_leaves': 54, 'min_child_samples': 7, 'subsample': 0.6381543200250853, 'colsample_bytree': 0.6362388077203682, 'reg_alpha': 8.137528199208804e-08, 'reg_lambda': 4.257159745197387e-08}. Best is trial 10 with value: 0.2828402145348072.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:21,807]\u001b[0m Trial 12 finished with value: 0.28273745510205817 and parameters: {'n_estimators': 401, 'learning_rate': 0.050241289258927374, 'num_leaves': 60, 'min_child_samples': 6, 'subsample': 0.607293588260076, 'colsample_bytree': 0.6041269199405257, 'reg_alpha': 1.4614377844063343e-08, 'reg_lambda': 1.2055866216717379e-08}. Best is trial 12 with value: 0.28273745510205817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:23,195]\u001b[0m Trial 13 finished with value: 0.2863362123303672 and parameters: {'n_estimators': 427, 'learning_rate': 0.1942249441302525, 'num_leaves': 58, 'min_child_samples': 15, 'subsample': 0.62382662441534, 'colsample_bytree': 0.6067155894908579, 'reg_alpha': 1.205041453602258e-08, 'reg_lambda': 1.4714974767119046e-08}. Best is trial 12 with value: 0.28273745510205817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:29,213]\u001b[0m Trial 14 finished with value: 0.28255807784699327 and parameters: {'n_estimators': 559, 'learning_rate': 0.035334702675807975, 'num_leaves': 65, 'min_child_samples': 5, 'subsample': 0.6013134930586377, 'colsample_bytree': 0.6813449232942006, 'reg_alpha': 1.2745215782856813e-08, 'reg_lambda': 3.822792099081491e-07}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:34,529]\u001b[0m Trial 15 finished with value: 0.2867542371509757 and parameters: {'n_estimators': 592, 'learning_rate': 0.032525985339934796, 'num_leaves': 69, 'min_child_samples': 59, 'subsample': 0.984708263265909, 'colsample_bytree': 0.6900833251933584, 'reg_alpha': 0.004987822669114498, 'reg_lambda': 5.677610835795586e-07}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:38,485]\u001b[0m Trial 16 finished with value: 0.2862621809969976 and parameters: {'n_estimators': 494, 'learning_rate': 0.02333401012751064, 'num_leaves': 11, 'min_child_samples': 80, 'subsample': 0.7082477347827287, 'colsample_bytree': 0.6817641651991246, 'reg_alpha': 3.235897726281591e-07, 'reg_lambda': 5.261334755527163e-07}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:53,490]\u001b[0m Trial 17 finished with value: 0.2853511174304256 and parameters: {'n_estimators': 586, 'learning_rate': 0.010313035020529368, 'num_leaves': 83, 'min_child_samples': 32, 'subsample': 0.6964999979329236, 'colsample_bytree': 0.6095168917732371, 'reg_alpha': 1.119048012544325e-05, 'reg_lambda': 1.092352608155723e-08}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:49:57,131]\u001b[0m Trial 18 finished with value: 0.28683248946054424 and parameters: {'n_estimators': 410, 'learning_rate': 0.0719924060023443, 'num_leaves': 101, 'min_child_samples': 17, 'subsample': 0.6020216566046899, 'colsample_bytree': 0.667249604450763, 'reg_alpha': 1.1131983333669773e-08, 'reg_lambda': 1.4798475299689957e-06}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:01,634]\u001b[0m Trial 19 finished with value: 0.28399257097644204 and parameters: {'n_estimators': 528, 'learning_rate': 0.03901268908496287, 'num_leaves': 63, 'min_child_samples': 15, 'subsample': 0.8073118738080323, 'colsample_bytree': 0.714292198024678, 'reg_alpha': 0.0016540631114142356, 'reg_lambda': 6.477945990465016e-08}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:06,089]\u001b[0m Trial 20 finished with value: 0.2827183474505309 and parameters: {'n_estimators': 446, 'learning_rate': 0.031813226549599206, 'num_leaves': 32, 'min_child_samples': 33, 'subsample': 0.6895806329372208, 'colsample_bytree': 0.6492118943810041, 'reg_alpha': 1.5941487373306058e-07, 'reg_lambda': 8.407543291638116e-08}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:11,770]\u001b[0m Trial 21 finished with value: 0.28299889436176096 and parameters: {'n_estimators': 461, 'learning_rate': 0.03252628543559054, 'num_leaves': 30, 'min_child_samples': 32, 'subsample': 0.6751310950558811, 'colsample_bytree': 0.6542685568367744, 'reg_alpha': 1.1687097564979094e-07, 'reg_lambda': 1.130456680437943e-07}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:18,971]\u001b[0m Trial 22 finished with value: 0.28279249353305247 and parameters: {'n_estimators': 380, 'learning_rate': 0.018540209973156932, 'num_leaves': 46, 'min_child_samples': 5, 'subsample': 0.6025639642352081, 'colsample_bytree': 0.7777287426410232, 'reg_alpha': 8.663201633406156e-08, 'reg_lambda': 2.841989455717004e-06}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:21,931]\u001b[0m Trial 23 finished with value: 0.2831170012215069 and parameters: {'n_estimators': 538, 'learning_rate': 0.046593240762681266, 'num_leaves': 35, 'min_child_samples': 23, 'subsample': 0.6693588459851506, 'colsample_bytree': 0.6398444366649514, 'reg_alpha': 1.5221996321942117e-06, 'reg_lambda': 8.100661121686157e-08}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:27,997]\u001b[0m Trial 24 finished with value: 0.2863731063659931 and parameters: {'n_estimators': 473, 'learning_rate': 0.029840452502340038, 'num_leaves': 73, 'min_child_samples': 55, 'subsample': 0.7249673153337204, 'colsample_bytree': 0.7058938747970567, 'reg_alpha': 4.990187846833559e-08, 'reg_lambda': 1.4476170154086675e-08}. Best is trial 14 with value: 0.28255807784699327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:30,125]\u001b[0m Trial 25 finished with value: 0.2810620139236291 and parameters: {'n_estimators': 506, 'learning_rate': 0.06843530196953905, 'num_leaves': 19, 'min_child_samples': 13, 'subsample': 0.648485901555079, 'colsample_bytree': 0.6068157511322381, 'reg_alpha': 2.2563677427730532e-07, 'reg_lambda': 2.641444880771134e-07}. Best is trial 25 with value: 0.2810620139236291.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:32,306]\u001b[0m Trial 26 finished with value: 0.2828744474039021 and parameters: {'n_estimators': 558, 'learning_rate': 0.062459177276190235, 'num_leaves': 21, 'min_child_samples': 33, 'subsample': 0.8183056187041062, 'colsample_bytree': 0.6406701826372588, 'reg_alpha': 2.1863923549673573e-05, 'reg_lambda': 2.054473590688756e-06}. Best is trial 25 with value: 0.2810620139236291.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:35,788]\u001b[0m Trial 27 finished with value: 0.28279379224052636 and parameters: {'n_estimators': 500, 'learning_rate': 0.036262175301461, 'num_leaves': 14, 'min_child_samples': 12, 'subsample': 0.6691181402868038, 'colsample_bytree': 0.8143796528779528, 'reg_alpha': 2.628656356086744e-07, 'reg_lambda': 0.00021091483020262462}. Best is trial 25 with value: 0.2810620139236291.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:38,880]\u001b[0m Trial 28 finished with value: 0.2926609137842971 and parameters: {'n_estimators': 447, 'learning_rate': 0.07263370267462806, 'num_leaves': 128, 'min_child_samples': 27, 'subsample': 0.7240539971877897, 'colsample_bytree': 0.9059897896393598, 'reg_alpha': 2.081403907796725e-06, 'reg_lambda': 2.2227398974940897e-07}. Best is trial 25 with value: 0.2810620139236291.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 16:50:42,814]\u001b[0m Trial 29 finished with value: 0.28233072228673356 and parameters: {'n_estimators': 505, 'learning_rate': 0.041225239034441245, 'num_leaves': 25, 'min_child_samples': 20, 'subsample': 0.6566952365255458, 'colsample_bytree': 0.7339203410599531, 'reg_alpha': 2.7105353729051594e-06, 'reg_lambda': 1.9987145235654047}. Best is trial 25 with value: 0.2810620139236291.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 25\n",
      "Best valid logloss: 0.2810620139236291\n",
      "Best params:\n",
      "{'n_estimators': 506, 'learning_rate': 0.06843530196953905, 'num_leaves': 19, 'min_child_samples': 13, 'subsample': 0.648485901555079, 'colsample_bytree': 0.6068157511322381, 'reg_alpha': 2.2563677427730532e-07, 'reg_lambda': 2.641444880771134e-07}\n"
     ]
    }
   ],
   "source": [
    "baseline_fold_df, baseline_summary_df, baseline_test_pred, baseline_test_proba = evaluate_pattern(\n",
    "    method_name='NoOptuna(FixedParams)',\n",
    "    custom_params=None\n",
    ")\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='lgbm_optuna_vs_no_optuna')\n",
    "study.optimize(optuna_objective, n_trials=N_TRIALS, timeout=TIMEOUT_SEC, show_progress_bar=False)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print('Best trial:', study.best_trial.number)\n",
    "print('Best valid logloss:', study.best_value)\n",
    "print('Best params:')\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0669aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11888\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 15628, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239314 -> initscore=-1.156444\n",
      "[LightGBM] [Info] Start training from score -1.156444\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n",
      "[LightGBM] [Info] Number of positive: 3740, number of negative: 11889\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 15629, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239299 -> initscore=-1.156528\n",
      "[LightGBM] [Info] Start training from score -1.156528\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoOptuna(FixedParams)</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.893914</td>\n",
       "      <td>0.845802</td>\n",
       "      <td>0.238141</td>\n",
       "      <td>0.951582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optuna(TunedParams)</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.890420</td>\n",
       "      <td>0.840161</td>\n",
       "      <td>0.242750</td>\n",
       "      <td>0.948807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoOptuna(FixedParams)</td>\n",
       "      <td>Valid</td>\n",
       "      <td>0.871365</td>\n",
       "      <td>0.812451</td>\n",
       "      <td>0.283001</td>\n",
       "      <td>0.925290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optuna(TunedParams)</td>\n",
       "      <td>Valid</td>\n",
       "      <td>0.871468</td>\n",
       "      <td>0.811899</td>\n",
       "      <td>0.281051</td>\n",
       "      <td>0.926295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoOptuna(FixedParams)</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.872524</td>\n",
       "      <td>0.814146</td>\n",
       "      <td>0.280934</td>\n",
       "      <td>0.926268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Optuna(TunedParams)</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.873480</td>\n",
       "      <td>0.814989</td>\n",
       "      <td>0.279046</td>\n",
       "      <td>0.927328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Method  Split  Accuracy  F1_macro   LogLoss       AUC\n",
       "0  NoOptuna(FixedParams)  Train  0.893914  0.845802  0.238141  0.951582\n",
       "1    Optuna(TunedParams)  Train  0.890420  0.840161  0.242750  0.948807\n",
       "2  NoOptuna(FixedParams)  Valid  0.871365  0.812451  0.283001  0.925290\n",
       "3    Optuna(TunedParams)  Valid  0.871468  0.811899  0.281051  0.926295\n",
       "4  NoOptuna(FixedParams)   Test  0.872524  0.814146  0.280934  0.926268\n",
       "5    Optuna(TunedParams)   Test  0.873480  0.814989  0.279046  0.927328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference by split (Optuna - NoOptuna)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy diff (Optuna - NoOptuna)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>-0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valid</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Accuracy diff (Optuna - NoOptuna)\n",
       "0  Train                          -0.003494\n",
       "1  Valid                           0.000102\n",
       "2   Test                           0.000955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna_fold_df, optuna_summary_df, optuna_test_pred, optuna_test_proba = evaluate_pattern(\n",
    "    method_name='Optuna(TunedParams)',\n",
    "    custom_params=best_params\n",
    ")\n",
    "\n",
    "comparison_df = pd.concat([baseline_summary_df, optuna_summary_df], ignore_index=True)\n",
    "comparison_df['Split'] = pd.Categorical(comparison_df['Split'], categories=['Train', 'Valid', 'Test'], ordered=True)\n",
    "comparison_df = comparison_df.sort_values(['Split', 'Method']).reset_index(drop=True)\n",
    "display(comparison_df)\n",
    "\n",
    "pivot_acc = comparison_df.pivot(index='Split', columns='Method', values='Accuracy')\n",
    "\n",
    "diff = pd.DataFrame({\n",
    "    'Accuracy diff (Optuna - NoOptuna)': pivot_acc['Optuna(TunedParams)'] - pivot_acc['NoOptuna(FixedParams)']\n",
    "}).reset_index()\n",
    "\n",
    "print('Difference by split (Optuna - NoOptuna)')\n",
    "display(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "521cd4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction agreement (NoOptuna vs Optuna): 0.9896\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agreement = (baseline_test_pred == optuna_test_pred).mean()\n",
    "print(f'Test prediction agreement (NoOptuna vs Optuna): {agreement:.4f}')\n",
    "\n",
    "split_order = ['Train', 'Valid', 'Test']\n",
    "x = np.arange(len(split_order))\n",
    "offset = 0.08\n",
    "\n",
    "acc_no = [pivot_acc.loc[s, 'NoOptuna(FixedParams)'] for s in split_order]\n",
    "acc_opt = [pivot_acc.loc[s, 'Optuna(TunedParams)'] for s in split_order]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax_right = ax.twinx()\n",
    "\n",
    "ax.set_xlim(-0.5, len(split_order) - 0.5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(split_order)\n",
    "ax.set_yticks([])\n",
    "ax.set_ylabel('')\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "\n",
    "ax_right.scatter(x - offset, acc_no, s=100, label='NoOptuna(FixedParams)', color='tab:blue')\n",
    "ax_right.scatter(x + offset, acc_opt, s=100, label='Optuna(TunedParams)', color='tab:orange')\n",
    "\n",
    "for i, score in enumerate(acc_no):\n",
    "    ax_right.text(x[i] - offset, score + 0.002, f'{score:.4f}', ha='center', va='bottom', fontsize=9, color='tab:blue')\n",
    "for i, score in enumerate(acc_opt):\n",
    "    ax_right.text(x[i] + offset, score + 0.002, f'{score:.4f}', ha='center', va='bottom', fontsize=9, color='tab:orange')\n",
    "\n",
    "all_acc = np.array(acc_no + acc_opt)\n",
    "ax_right.set_ylabel('Accuracy')\n",
    "ax_right.set_ylim(max(0.0, all_acc.min() - 0.02), min(1.0, all_acc.max() + 0.02))\n",
    "ax_right.legend(loc='lower left')  \n",
    "\n",
    "plt.title('NoOptuna vs Optuna (StratifiedKFold)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
