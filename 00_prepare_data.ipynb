{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f08008f",
   "metadata": {},
   "source": [
    "# 00 Prepare Data (Titanic)\n",
    "\n",
    "`sklearn.datasets.fetch_openml` で Titanic データを取得し、前処理したうえで以降のNotebookで共通利用する Train/Test を作成して保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b50eca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:\n",
      "{'task_type': 'classification', 'dataset_id': 'adult_openml_v2', 'test_size': 0.6, 'random_seed': 42, 'enable_distribution_noise': True, 'noise_mode': 'segment_shift_and_label_flip', 'noise_feature_count': 1, 'noise_strength': 0.5, 'noise_random_seed': 49, 'noise_segment_fraction': 0.15, 'noise_label_flip_rate': 0.3}\n",
      "Output train path: data/processed/classification_train.csv\n",
      "Output test path : data/processed/classification_test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CONFIG_PATH = Path('config/dataset_config.json')\n",
    "OUTPUT_DIR = Path('data/processed')\n",
    "TRAIN_PATH = OUTPUT_DIR / 'classification_train.csv'\n",
    "TEST_PATH = OUTPUT_DIR / 'classification_test.csv'\n",
    "META_PATH = OUTPUT_DIR / 'classification_meta.json'\n",
    "\n",
    "SUPPORTED_CLASSIFICATION_DATASETS = {\n",
    "    'titanic_openml_v1',\n",
    "    'adult_openml_v2',\n",
    "    'bank_openml_1461',\n",
    "    'steel_openml_1504',\n",
    "    'fraud_openml_1597',\n",
    "    'steel_openml_1597',\n",
    "    'wine_sklearn',\n",
    "    'breast_cancer_sklearn'\n",
    "}\n",
    "\n",
    "config = json.loads(CONFIG_PATH.read_text(encoding='utf-8'))\n",
    "task_type = str(config.get('task_type', 'classification')).lower()\n",
    "dataset_id = str(config.get('dataset_id', 'titanic_openml_v1'))\n",
    "SEED = int(config.get('random_seed', 42))\n",
    "TEST_SIZE = float(config.get('test_size', 0.2))\n",
    "ENABLE_DISTRIBUTION_NOISE = bool(config.get('enable_distribution_noise', False))\n",
    "NOISE_MODE = str(config.get('noise_mode', 'gaussian_shift'))\n",
    "NOISE_FEATURE_COUNT = int(config.get('noise_feature_count', 1))\n",
    "NOISE_STRENGTH = float(config.get('noise_strength', 0.5))\n",
    "NOISE_RANDOM_SEED = int(config.get('noise_random_seed', SEED + 7))\n",
    "NOISE_SEGMENT_FRACTION = float(config.get('noise_segment_fraction', 0.15))\n",
    "NOISE_LABEL_FLIP_RATE = float(config.get('noise_label_flip_rate', 0.30))\n",
    "\n",
    "SUPPORTED_NOISE_MODES = {\n",
    "    'gaussian_shift',\n",
    "    'segment_shift',\n",
    "    'segment_label_flip',\n",
    "    'segment_shift_and_label_flip'\n",
    "}\n",
    "\n",
    "if task_type != 'classification':\n",
    "    raise ValueError(f\"Only classification is supported. Received task_type={task_type}\")\n",
    "if dataset_id not in SUPPORTED_CLASSIFICATION_DATASETS:\n",
    "    raise ValueError(f\"Unsupported dataset_id: {dataset_id}. Supported: {sorted(SUPPORTED_CLASSIFICATION_DATASETS)}\")\n",
    "if not (0.0 < TEST_SIZE < 1.0):\n",
    "    raise ValueError(f\"test_size must be in (0, 1). Received: {TEST_SIZE}\")\n",
    "if NOISE_FEATURE_COUNT not in [1, 2]:\n",
    "    raise ValueError(f\"noise_feature_count must be 1 or 2. Received: {NOISE_FEATURE_COUNT}\")\n",
    "if NOISE_STRENGTH <= 0:\n",
    "    raise ValueError(f\"noise_strength must be > 0. Received: {NOISE_STRENGTH}\")\n",
    "if NOISE_MODE not in SUPPORTED_NOISE_MODES:\n",
    "    raise ValueError(f\"noise_mode must be one of {sorted(SUPPORTED_NOISE_MODES)}. Received: {NOISE_MODE}\")\n",
    "if not (0.0 < NOISE_SEGMENT_FRACTION < 1.0):\n",
    "    raise ValueError(f\"noise_segment_fraction must be in (0,1). Received: {NOISE_SEGMENT_FRACTION}\")\n",
    "if not (0.0 <= NOISE_LABEL_FLIP_RATE <= 1.0):\n",
    "    raise ValueError(f\"noise_label_flip_rate must be in [0,1]. Received: {NOISE_LABEL_FLIP_RATE}\")\n",
    "\n",
    "print('Loaded config:')\n",
    "print(config)\n",
    "print(f'Output train path: {TRAIN_PATH}')\n",
    "print(f'Output test path : {TEST_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "473c8933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution noise is enabled.\n",
      "Noise mode: segment_shift_and_label_flip\n",
      "Noise applied features: ['age']\n",
      "Noise segment fraction: 0.15\n",
      "Label flipped count: 2223\n",
      "Dataset: openml_adult_v2\n",
      "Full dataset shape: (48842, 15)\n",
      "Class ratio: {0: 0.736620122026125, 1: 0.26337987797387497}\n",
      "Feature count after preprocessing: 14\n"
     ]
    }
   ],
   "source": [
    "# 分類データセットを設定ファイルに基づいてロード\n",
    "if dataset_id == 'titanic_openml_v1':\n",
    "    ds = fetch_openml('titanic', version=1, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_titanic_v1'\n",
    "elif dataset_id == 'adult_openml_v2':\n",
    "    ds = fetch_openml('adult', version=2, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_adult_v2'\n",
    "elif dataset_id == 'bank_openml_1461':\n",
    "    # OpenML ID 1461: Bank Marketing\n",
    "    ds = fetch_openml(data_id=1461, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_bank_marketing_1461'\n",
    "elif dataset_id == 'steel_openml_1504':\n",
    "    # OpenML ID 1504: Steel Plates Faults\n",
    "    ds = fetch_openml(data_id=1504, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_steel_1504'\n",
    "elif dataset_id in ['fraud_openml_1597', 'steel_openml_1597']:\n",
    "    # OpenML ID 1597: Credit Card Fraud Detection\n",
    "    ds = fetch_openml(data_id=1597, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_fraud_1597'\n",
    "elif dataset_id == 'wine_sklearn':\n",
    "    ds = load_wine(as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'sklearn_load_wine'\n",
    "elif dataset_id == 'breast_cancer_sklearn':\n",
    "    ds = load_breast_cancer(as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'sklearn_load_breast_cancer'\n",
    "else:\n",
    "    raise ValueError(f'Unsupported dataset_id: {dataset_id}')\n",
    "\n",
    "# 目的変数を分類ラベルとして整数エンコード\n",
    "y_cat = pd.Series(y_raw).astype('category')\n",
    "target_names = [str(v) for v in y_cat.cat.categories]\n",
    "y = y_cat.cat.codes.astype(int)\n",
    "if y.nunique() < 2:\n",
    "    raise ValueError('Classification requires at least 2 classes in target.')\n",
    "\n",
    "# 数値列: 欠損を中央値で補完\n",
    "num_cols = X_raw.select_dtypes(include=['number']).columns.tolist()\n",
    "X_num = X_raw[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "X_num = X_num.fillna(X_num.median())\n",
    "\n",
    "# カテゴリ列: 欠損を'missing'で補完し、カテゴリコード化（ダミー化はしない）\n",
    "cat_cols = [c for c in X_raw.columns if c not in num_cols]\n",
    "X_cat = X_raw[cat_cols].astype('string').fillna('missing')\n",
    "X_cat_encoded = pd.DataFrame(index=X_raw.index)\n",
    "for col in cat_cols:\n",
    "    X_cat_encoded[col] = X_cat[col].astype('category').cat.codes.astype('int32')\n",
    "\n",
    "X = pd.concat([X_num, X_cat_encoded], axis=1)\n",
    "\n",
    "# オプション: 学習を難しくするために特徴量分布へノイズ注入\n",
    "noise_applied_features = []\n",
    "label_flipped_count = 0\n",
    "if ENABLE_DISTRIBUTION_NOISE:\n",
    "    rng = np.random.default_rng(NOISE_RANDOM_SEED)\n",
    "    noise_feature_count = min(NOISE_FEATURE_COUNT, X.shape[1])\n",
    "    noise_applied_features = rng.choice(X.columns.to_numpy(), size=noise_feature_count, replace=False).tolist()\n",
    "    segment_mask = rng.random(len(X)) < NOISE_SEGMENT_FRACTION\n",
    "    classes = np.sort(y.unique())\n",
    "\n",
    "    for feature in noise_applied_features:\n",
    "        X[feature] = pd.to_numeric(X[feature], errors='coerce').astype(float)\n",
    "        values = X[feature]\n",
    "        finite_std = float(np.nanstd(values))\n",
    "        if not np.isfinite(finite_std) or finite_std == 0.0:\n",
    "            finite_std = 1.0\n",
    "\n",
    "        if NOISE_MODE == 'gaussian_shift':\n",
    "            affected_mask = rng.random(len(X)) < 0.35\n",
    "            noise = rng.normal(loc=0.0, scale=NOISE_STRENGTH * finite_std, size=int(affected_mask.sum()))\n",
    "            shifted = values.loc[affected_mask] + noise + (NOISE_STRENGTH * finite_std * 1.5)\n",
    "            X.loc[affected_mask, feature] = shifted.values\n",
    "        elif NOISE_MODE in ['segment_shift', 'segment_shift_and_label_flip']:\n",
    "            noise = rng.normal(loc=0.0, scale=NOISE_STRENGTH * finite_std, size=int(segment_mask.sum()))\n",
    "            shifted = values.loc[segment_mask] + noise + (NOISE_STRENGTH * finite_std * 3.0)\n",
    "            X.loc[segment_mask, feature] = shifted.values\n",
    "\n",
    "    if NOISE_MODE in ['segment_label_flip', 'segment_shift_and_label_flip']:\n",
    "        flip_mask = segment_mask & (rng.random(len(X)) < NOISE_LABEL_FLIP_RATE)\n",
    "        label_flipped_count = int(flip_mask.sum())\n",
    "        if label_flipped_count > 0:\n",
    "            if len(classes) == 2:\n",
    "                y.loc[flip_mask] = 1 - y.loc[flip_mask].astype(int)\n",
    "            else:\n",
    "                current = y.loc[flip_mask].to_numpy()\n",
    "                replaced = []\n",
    "                for cur in current:\n",
    "                    candidates = classes[classes != cur]\n",
    "                    replaced.append(int(rng.choice(candidates)))\n",
    "                y.loc[flip_mask] = replaced\n",
    "\n",
    "    print('Distribution noise is enabled.')\n",
    "    print('Noise mode:', NOISE_MODE)\n",
    "    print('Noise applied features:', noise_applied_features)\n",
    "    print('Noise segment fraction:', NOISE_SEGMENT_FRACTION)\n",
    "    print('Label flipped count:', label_flipped_count)\n",
    "else:\n",
    "    print('Distribution noise is disabled.')\n",
    "\n",
    "# LightGBMで安全に扱えるよう列名を正規化\n",
    "def sanitize_column_name(col):\n",
    "    col = str(col)\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]+', '_', col)\n",
    "    col = re.sub(r'_+', '_', col).strip('_')\n",
    "    if col == '':\n",
    "        col = 'col'\n",
    "    if col[0].isdigit():\n",
    "        col = f'f_{col}'\n",
    "    return col\n",
    "\n",
    "sanitized_cols = [sanitize_column_name(c) for c in X.columns]\n",
    "seen = {}\n",
    "unique_cols = []\n",
    "for c in sanitized_cols:\n",
    "    seen[c] = seen.get(c, 0) + 1\n",
    "    unique_cols.append(c if seen[c] == 1 else f'{c}_{seen[c]-1}')\n",
    "X.columns = unique_cols\n",
    "\n",
    "df = X.copy()\n",
    "df['target'] = y\n",
    "\n",
    "print(f'Dataset: {dataset_name}')\n",
    "print(f'Full dataset shape: {df.shape}')\n",
    "print('Class ratio:', y.value_counts(normalize=True).sort_index().to_dict())\n",
    "print(f'Feature count after preprocessing: {X.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "162de060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (19536, 15)\n",
      "Test shape : (29306, 15)\n",
      "Train class ratio: {0: 0.7366400491400491, 1: 0.26335995085995084}\n",
      "Test  class ratio: {0: 0.7366068381901317, 1: 0.26339316180986827}\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=df['target']\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "print(f'Test shape : {test_df.shape}')\n",
    "print('Train class ratio:', train_df['target'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Test  class ratio:', test_df['target'].value_counts(normalize=True).sort_index().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdfd2ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/processed/classification_train.csv\n",
      "Saved: data/processed/classification_test.csv\n",
      "Saved: data/processed/classification_meta.json\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(TRAIN_PATH, index=False)\n",
    "test_df.to_csv(TEST_PATH, index=False)\n",
    "\n",
    "meta = {\n",
    "    'dataset': dataset_name,\n",
    "    'dataset_id': dataset_id,\n",
    "    'task_type': task_type,\n",
    "    'seed': SEED,\n",
    "    'test_size': TEST_SIZE,\n",
    "    'enable_distribution_noise': ENABLE_DISTRIBUTION_NOISE,\n",
    "    'noise_mode': NOISE_MODE,\n",
    "    'noise_feature_count': NOISE_FEATURE_COUNT,\n",
    "    'noise_strength': NOISE_STRENGTH,\n",
    "    'noise_random_seed': NOISE_RANDOM_SEED,\n",
    "    'noise_segment_fraction': NOISE_SEGMENT_FRACTION,\n",
    "    'noise_label_flip_rate': NOISE_LABEL_FLIP_RATE,\n",
    "    'noise_applied_features': noise_applied_features,\n",
    "    'label_flipped_count': label_flipped_count,\n",
    "    'n_samples_total': int(df.shape[0]),\n",
    "    'n_samples_train': int(train_df.shape[0]),\n",
    "    'n_samples_test': int(test_df.shape[0]),\n",
    "    'n_features': int(X.shape[1]),\n",
    "    'feature_names': list(X.columns),\n",
    "    'target_names': target_names,\n",
    "    'class_labels': sorted(train_df['target'].unique().tolist())\n",
    "}\n",
    "META_PATH.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding='utf-8')\n",
    "\n",
    "print(f'Saved: {TRAIN_PATH}')\n",
    "print(f'Saved: {TEST_PATH}')\n",
    "print(f'Saved: {META_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "450475fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>152641</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.121177</td>\n",
       "      <td>49715</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>125892</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>223792</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>99399</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "0  18.000000  152641              6             0             0   \n",
       "1  84.121177   49715              9             0             0   \n",
       "2  46.000000  125892             13             0          1977   \n",
       "3  39.000000  223792              9             0             0   \n",
       "4  23.000000   99399             10             0             0   \n",
       "\n",
       "   hours_per_week  workclass  education  marital_status  occupation  \\\n",
       "0              40          8          0               4          14   \n",
       "1              40          3         11               0          13   \n",
       "2              60          4          9               2           9   \n",
       "3              40          3         11               2           6   \n",
       "4              25          8         15               4          14   \n",
       "\n",
       "   relationship  race  sex  native_country  target  \n",
       "0             3     4    1              38       0  \n",
       "1             4     4    1              38       0  \n",
       "2             0     4    1              38       1  \n",
       "3             0     4    1              38       1  \n",
       "4             4     0    0              38       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>44308</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>24244</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>119254</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>103323</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.687579</td>\n",
       "      <td>91608</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "0  26.000000   44308             13             0             0   \n",
       "1  59.000000   24244             10             0             0   \n",
       "2  56.000000  119254              6             0             0   \n",
       "3  37.000000  103323              9             0             0   \n",
       "4  66.687579   91608             15             0             0   \n",
       "\n",
       "   hours_per_week  workclass  education  marital_status  occupation  \\\n",
       "0              40          3          9               4          12   \n",
       "1              40          3         15               0           7   \n",
       "2              40          8          0               0          14   \n",
       "3              40          3         11               4           2   \n",
       "4              40          3         14               2           2   \n",
       "\n",
       "   relationship  race  sex  native_country  target  \n",
       "0             1     4    1              38       0  \n",
       "1             1     4    0              38       0  \n",
       "2             1     4    0              38       0  \n",
       "3             1     4    1              38       0  \n",
       "4             0     4    1              38       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
