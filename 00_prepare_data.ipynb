{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f08008f",
   "metadata": {},
   "source": [
    "# 00 Prepare Data (Titanic)\n",
    "\n",
    "`sklearn.datasets.fetch_openml` で Titanic データを取得し、前処理したうえで以降のNotebookで共通利用する Train/Test を作成して保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b50eca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:\n",
      "{'task_type': 'classification', 'dataset_id': 'adult_openml_v2', 'test_size': 0.6, 'random_seed': 42, 'enable_distribution_noise': False, 'noise_mode': 'segment_shift_and_label_flip', 'noise_feature_count': 2, 'noise_strength': 0.5, 'noise_random_seed': 20, 'noise_segment_fraction': 0.4, 'noise_label_flip_rate': 0.6}\n",
      "Output train path: data/processed/classification_train.csv\n",
      "Output test path : data/processed/classification_test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CONFIG_PATH = Path('config/dataset_config.json')\n",
    "OUTPUT_DIR = Path('data/processed')\n",
    "TRAIN_PATH = OUTPUT_DIR / 'classification_train.csv'\n",
    "TEST_PATH = OUTPUT_DIR / 'classification_test.csv'\n",
    "META_PATH = OUTPUT_DIR / 'classification_meta.json'\n",
    "\n",
    "SUPPORTED_CLASSIFICATION_DATASETS = {\n",
    "    'titanic_openml_v1',\n",
    "    'adult_openml_v2',\n",
    "    'bank_openml_1461',\n",
    "    'steel_openml_1504',\n",
    "    'fraud_openml_1597',\n",
    "    'steel_openml_1597',\n",
    "    'wine_sklearn',\n",
    "    'breast_cancer_sklearn'\n",
    "}\n",
    "\n",
    "config = json.loads(CONFIG_PATH.read_text(encoding='utf-8'))\n",
    "task_type = str(config.get('task_type', 'classification')).lower()\n",
    "dataset_id = str(config.get('dataset_id', 'titanic_openml_v1'))\n",
    "SEED = int(config.get('random_seed', 42))\n",
    "TEST_SIZE = float(config.get('test_size', 0.2))\n",
    "ENABLE_DISTRIBUTION_NOISE = bool(config.get('enable_distribution_noise', False))\n",
    "NOISE_MODE = str(config.get('noise_mode', 'gaussian_shift'))\n",
    "NOISE_FEATURE_COUNT = int(config.get('noise_feature_count', 1))\n",
    "NOISE_STRENGTH = float(config.get('noise_strength', 0.5))\n",
    "NOISE_RANDOM_SEED = int(config.get('noise_random_seed', SEED + 7))\n",
    "NOISE_SEGMENT_FRACTION = float(config.get('noise_segment_fraction', 0.15))\n",
    "NOISE_LABEL_FLIP_RATE = float(config.get('noise_label_flip_rate', 0.30))\n",
    "\n",
    "SUPPORTED_NOISE_MODES = {\n",
    "    'gaussian_shift',\n",
    "    'segment_shift',\n",
    "    'segment_label_flip',\n",
    "    'segment_shift_and_label_flip'\n",
    "}\n",
    "\n",
    "if task_type != 'classification':\n",
    "    raise ValueError(f\"Only classification is supported. Received task_type={task_type}\")\n",
    "if dataset_id not in SUPPORTED_CLASSIFICATION_DATASETS:\n",
    "    raise ValueError(f\"Unsupported dataset_id: {dataset_id}. Supported: {sorted(SUPPORTED_CLASSIFICATION_DATASETS)}\")\n",
    "if not (0.0 < TEST_SIZE < 1.0):\n",
    "    raise ValueError(f\"test_size must be in (0, 1). Received: {TEST_SIZE}\")\n",
    "if NOISE_FEATURE_COUNT not in [1, 2]:\n",
    "    raise ValueError(f\"noise_feature_count must be 1 or 2. Received: {NOISE_FEATURE_COUNT}\")\n",
    "if NOISE_STRENGTH <= 0:\n",
    "    raise ValueError(f\"noise_strength must be > 0. Received: {NOISE_STRENGTH}\")\n",
    "if NOISE_MODE not in SUPPORTED_NOISE_MODES:\n",
    "    raise ValueError(f\"noise_mode must be one of {sorted(SUPPORTED_NOISE_MODES)}. Received: {NOISE_MODE}\")\n",
    "if not (0.0 < NOISE_SEGMENT_FRACTION < 1.0):\n",
    "    raise ValueError(f\"noise_segment_fraction must be in (0,1). Received: {NOISE_SEGMENT_FRACTION}\")\n",
    "if not (0.0 <= NOISE_LABEL_FLIP_RATE <= 1.0):\n",
    "    raise ValueError(f\"noise_label_flip_rate must be in [0,1]. Received: {NOISE_LABEL_FLIP_RATE}\")\n",
    "\n",
    "print('Loaded config:')\n",
    "print(config)\n",
    "print(f'Output train path: {TRAIN_PATH}')\n",
    "print(f'Output test path : {TEST_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "473c8933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: openml_adult_v2\n",
      "Full dataset shape: (48842, 15)\n",
      "Class ratio: {0: 0.7607182343065395, 1: 0.23928176569346055}\n",
      "Feature count after preprocessing: 14\n"
     ]
    }
   ],
   "source": [
    "# 分類データセットを設定ファイルに基づいてロード\n",
    "if dataset_id == 'titanic_openml_v1':\n",
    "    ds = fetch_openml('titanic', version=1, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_titanic_v1'\n",
    "elif dataset_id == 'adult_openml_v2':\n",
    "    ds = fetch_openml('adult', version=2, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_adult_v2'\n",
    "elif dataset_id == 'bank_openml_1461':\n",
    "    # OpenML ID 1461: Bank Marketing\n",
    "    ds = fetch_openml(data_id=1461, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_bank_marketing_1461'\n",
    "elif dataset_id == 'steel_openml_1504':\n",
    "    # OpenML ID 1504: Steel Plates Faults\n",
    "    ds = fetch_openml(data_id=1504, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_steel_1504'\n",
    "elif dataset_id in ['fraud_openml_1597', 'steel_openml_1597']:\n",
    "    # OpenML ID 1597: Credit Card Fraud Detection\n",
    "    ds = fetch_openml(data_id=1597, as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'openml_fraud_1597'\n",
    "elif dataset_id == 'wine_sklearn':\n",
    "    ds = load_wine(as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'sklearn_load_wine'\n",
    "elif dataset_id == 'breast_cancer_sklearn':\n",
    "    ds = load_breast_cancer(as_frame=True)\n",
    "    X_raw = ds.data.copy()\n",
    "    y_raw = ds.target.copy()\n",
    "    dataset_name = 'sklearn_load_breast_cancer'\n",
    "else:\n",
    "    raise ValueError(f'Unsupported dataset_id: {dataset_id}')\n",
    "\n",
    "# 目的変数を分類ラベルとして整数エンコード\n",
    "y_cat = pd.Series(y_raw).astype('category')\n",
    "target_names = [str(v) for v in y_cat.cat.categories]\n",
    "y = y_cat.cat.codes.astype(int)\n",
    "if y.nunique() < 2:\n",
    "    raise ValueError('Classification requires at least 2 classes in target.')\n",
    "\n",
    "# 数値列: 欠損を中央値で補完\n",
    "num_cols = X_raw.select_dtypes(include=['number']).columns.tolist()\n",
    "X_num = X_raw[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "X_num = X_num.fillna(X_num.median())\n",
    "\n",
    "# カテゴリ列: 欠損を'missing'で補完し、カテゴリコード化（ダミー化はしない）\n",
    "cat_cols = [c for c in X_raw.columns if c not in num_cols]\n",
    "X_cat = X_raw[cat_cols].astype('string').fillna('missing')\n",
    "X_cat_encoded = pd.DataFrame(index=X_raw.index)\n",
    "for col in cat_cols:\n",
    "    X_cat_encoded[col] = X_cat[col].astype('category').cat.codes.astype('int32')\n",
    "\n",
    "X = pd.concat([X_num, X_cat_encoded], axis=1)\n",
    "\n",
    "# LightGBMで安全に扱えるよう列名を正規化\n",
    "def sanitize_column_name(col):\n",
    "    col = str(col)\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]+', '_', col)\n",
    "    col = re.sub(r'_+', '_', col).strip('_')\n",
    "    if col == '':\n",
    "        col = 'col'\n",
    "    if col[0].isdigit():\n",
    "        col = f'f_{col}'\n",
    "    return col\n",
    "\n",
    "sanitized_cols = [sanitize_column_name(c) for c in X.columns]\n",
    "seen = {}\n",
    "unique_cols = []\n",
    "for c in sanitized_cols:\n",
    "    seen[c] = seen.get(c, 0) + 1\n",
    "    unique_cols.append(c if seen[c] == 1 else f'{c}_{seen[c]-1}')\n",
    "X.columns = unique_cols\n",
    "\n",
    "df = X.copy()\n",
    "df['target'] = y\n",
    "\n",
    "print(f'Dataset: {dataset_name}')\n",
    "print(f'Full dataset shape: {df.shape}')\n",
    "print('Class ratio:', y.value_counts(normalize=True).sort_index().to_dict())\n",
    "print(f'Feature count after preprocessing: {X.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "162de060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution noise is disabled.\n",
      "Train shape: (19536, 15)\n",
      "Test shape : (29306, 15)\n",
      "Train class ratio: {0: 0.7606981981981982, 1: 0.2393018018018018}\n",
      "Test  class ratio: {0: 0.7607315908005187, 1: 0.23926840919948134}\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=df['target']\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "noise_applied_features = []\n",
    "label_flipped_count = 0\n",
    "\n",
    "if ENABLE_DISTRIBUTION_NOISE:\n",
    "    rng = np.random.default_rng(NOISE_RANDOM_SEED)\n",
    "    feature_pool = [c for c in train_df.columns if c != 'target']\n",
    "    noise_feature_count = min(NOISE_FEATURE_COUNT, len(feature_pool))\n",
    "    noise_applied_features = rng.choice(np.array(feature_pool), size=noise_feature_count, replace=False).tolist()\n",
    "\n",
    "    segment_mask = rng.random(len(test_df)) < NOISE_SEGMENT_FRACTION\n",
    "    classes = np.sort(train_df['target'].unique())\n",
    "\n",
    "    for feature in noise_applied_features:\n",
    "        test_df[feature] = pd.to_numeric(test_df[feature], errors='coerce').astype(float)\n",
    "        train_feature_std = float(np.nanstd(pd.to_numeric(train_df[feature], errors='coerce')))\n",
    "        if not np.isfinite(train_feature_std) or train_feature_std == 0.0:\n",
    "            train_feature_std = float(np.nanstd(test_df[feature]))\n",
    "        if not np.isfinite(train_feature_std) or train_feature_std == 0.0:\n",
    "            train_feature_std = 1.0\n",
    "\n",
    "        if NOISE_MODE == 'gaussian_shift':\n",
    "            affected_mask = rng.random(len(test_df)) < 0.35\n",
    "            noise = rng.normal(loc=0.0, scale=NOISE_STRENGTH * train_feature_std, size=int(affected_mask.sum()))\n",
    "            shifted = test_df.loc[affected_mask, feature] + noise + (NOISE_STRENGTH * train_feature_std * 1.5)\n",
    "            test_df.loc[affected_mask, feature] = shifted.values\n",
    "        elif NOISE_MODE in ['segment_shift', 'segment_shift_and_label_flip']:\n",
    "            noise = rng.normal(loc=0.0, scale=NOISE_STRENGTH * train_feature_std, size=int(segment_mask.sum()))\n",
    "            shifted = test_df.loc[segment_mask, feature] + noise + (NOISE_STRENGTH * train_feature_std * 3.0)\n",
    "            test_df.loc[segment_mask, feature] = shifted.values\n",
    "\n",
    "    if NOISE_MODE in ['segment_label_flip', 'segment_shift_and_label_flip']:\n",
    "        flip_mask = segment_mask & (rng.random(len(test_df)) < NOISE_LABEL_FLIP_RATE)\n",
    "        label_flipped_count = int(flip_mask.sum())\n",
    "        if label_flipped_count > 0:\n",
    "            if len(classes) == 2:\n",
    "                test_df.loc[flip_mask, 'target'] = 1 - test_df.loc[flip_mask, 'target'].astype(int)\n",
    "            else:\n",
    "                current = test_df.loc[flip_mask, 'target'].to_numpy()\n",
    "                replaced = []\n",
    "                for cur in current:\n",
    "                    candidates = classes[classes != cur]\n",
    "                    replaced.append(int(rng.choice(candidates)))\n",
    "                test_df.loc[flip_mask, 'target'] = replaced\n",
    "\n",
    "    print('Distribution noise is enabled (applied to Test only).')\n",
    "    print('Noise mode:', NOISE_MODE)\n",
    "    print('Noise applied features:', noise_applied_features)\n",
    "    print('Noise segment fraction:', NOISE_SEGMENT_FRACTION)\n",
    "    print('Label flipped count:', label_flipped_count)\n",
    "else:\n",
    "    print('Distribution noise is disabled.')\n",
    "\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "print(f'Test shape : {test_df.shape}')\n",
    "print('Train class ratio:', train_df['target'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Test  class ratio:', test_df['target'].value_counts(normalize=True).sort_index().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fdfd2ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/processed/classification_train.csv\n",
      "Saved: data/processed/classification_test.csv\n",
      "Saved: data/processed/classification_meta.json\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(TRAIN_PATH, index=False)\n",
    "test_df.to_csv(TEST_PATH, index=False)\n",
    "\n",
    "meta = {\n",
    "    'dataset': dataset_name,\n",
    "    'dataset_id': dataset_id,\n",
    "    'task_type': task_type,\n",
    "    'seed': SEED,\n",
    "    'test_size': TEST_SIZE,\n",
    "    'enable_distribution_noise': ENABLE_DISTRIBUTION_NOISE,\n",
    "    'noise_mode': NOISE_MODE,\n",
    "    'noise_feature_count': NOISE_FEATURE_COUNT,\n",
    "    'noise_strength': NOISE_STRENGTH,\n",
    "    'noise_random_seed': NOISE_RANDOM_SEED,\n",
    "    'noise_segment_fraction': NOISE_SEGMENT_FRACTION,\n",
    "    'noise_label_flip_rate': NOISE_LABEL_FLIP_RATE,\n",
    "    'noise_applied_features': noise_applied_features,\n",
    "    'label_flipped_count': label_flipped_count,\n",
    "    'n_samples_total': int(df.shape[0]),\n",
    "    'n_samples_train': int(train_df.shape[0]),\n",
    "    'n_samples_test': int(test_df.shape[0]),\n",
    "    'n_features': int(X.shape[1]),\n",
    "    'feature_names': list(X.columns),\n",
    "    'target_names': target_names,\n",
    "    'class_labels': sorted(train_df['target'].unique().tolist())\n",
    "}\n",
    "META_PATH.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding='utf-8')\n",
    "\n",
    "print(f'Saved: {TRAIN_PATH}')\n",
    "print(f'Saved: {TEST_PATH}')\n",
    "print(f'Saved: {META_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "450475fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>22494</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>129762</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>182186</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>169182</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>318264</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
       "0   36   22494             10             0             0              40   \n",
       "1   55  129762              9             0             0              40   \n",
       "2   53  182186              5             0             0              40   \n",
       "3   51  169182              5             0             0              45   \n",
       "4   19  318264             10             0             0              30   \n",
       "\n",
       "   workclass  education  marital_status  occupation  relationship  race  sex  \\\n",
       "0          3         15               0           3             4     4    0   \n",
       "1          3         11               0           0             4     4    0   \n",
       "2          3          6               2           7             0     4    1   \n",
       "3          1          6               6           7             1     4    0   \n",
       "4          8         15               4          14             3     4    1   \n",
       "\n",
       "   native_country  target  \n",
       "0              38       0  \n",
       "1              38       0  \n",
       "2               5       0  \n",
       "3               4       0  \n",
       "4              38       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>125892</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>320984</td>\n",
       "      <td>10</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>116788</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>211391</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>166107</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
       "0   47  125892              9             0             0              40   \n",
       "1   44  320984             10          5178             0              60   \n",
       "2   21  116788              9             0             0              40   \n",
       "3   20  211391             10             0             0              25   \n",
       "4   45  166107             14             0             0              40   \n",
       "\n",
       "   workclass  education  marital_status  occupation  relationship  race  sex  \\\n",
       "0          3         11               0           5             1     4    1   \n",
       "1          4         15               2          11             0     4    1   \n",
       "2          3         11               4           2             3     4    1   \n",
       "3          3         15               4          11             1     4    0   \n",
       "4          3         12               4           0             1     1    0   \n",
       "\n",
       "   native_country  target  \n",
       "0              38       0  \n",
       "1              38       1  \n",
       "2              38       0  \n",
       "3              38       0  \n",
       "4              29       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
